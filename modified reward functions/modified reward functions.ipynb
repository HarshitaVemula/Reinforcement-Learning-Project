{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citylearn import  CityLearn\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment\n",
    "data_folder = Path(\"data/\")\n",
    "building_attributes = data_folder / 'building_attributes.json'\n",
    "solar_profile = data_folder / 'solar_generation_1kW.csv'\n",
    "building_state_actions = 'buildings_state_action_space.json'\n",
    "#building_ids = [\"Building_1\",\"Building_2\",\"Building_3\",\"Building_4\",\"Building_5\",\"Building_6\",\"Building_7\",\"Building_8\",\"Building_9\"]\n",
    "building_ids = [\"Building_1\"]\n",
    "env = CityLearn(building_attributes, solar_profile, building_ids, buildings_states_actions = building_state_actions, cost_function = ['ramping','1-load_factor','peak_to_valley_ratio','peak_demand','net_electricity_consumption'])\n",
    "observations_spaces,actions_spaces = env.get_state_action_spaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2,  0. ,  0.2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_space=np.arange(-0.2,0.21,0.2)\n",
    "actions_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_space=np.arange(-0.2,0.21,0.2)\n",
    "num_actions=actions_space.shape[0]\n",
    "def generate_state(state):\n",
    "    l=np.zeros(24)\n",
    "    l[int(state)-1]=1\n",
    "    return(l)\n",
    "#reward fucntion 1\n",
    "def reward_fun1(hr,action):\n",
    "    if hr in np.arange(2,10):\n",
    "        if action>0:\n",
    "            reward=10\n",
    "        else:\n",
    "            reward=-10\n",
    "    elif hr in np.arange(10,12):\n",
    "        if action==0:\n",
    "            reward=10\n",
    "        else:\n",
    "            reward=-10\n",
    "    elif hr in np.arange(12,20):\n",
    "        if action<0:\n",
    "            reward=10\n",
    "        else:\n",
    "            reward=-10\n",
    "    else:\n",
    "        if action==0:\n",
    "            reward=10\n",
    "        else:\n",
    "            reward=-10\n",
    "    return(reward)\n",
    "#reward fucntion 2\n",
    "def reward_comparitive2(lister):\n",
    "    if lister[0]<lister[1]:\n",
    "        return(-10)\n",
    "    else:\n",
    "        return(10)\n",
    "\n",
    "#reward_function 3\n",
    "def reward_fun4(mu,temp_diff,action,soc,epsilon=0.01):\n",
    "    p=np.sign(mu-temp_diff)\n",
    "    a=(p+1)*action\n",
    "    b=p*(np.sign(soc+p*action-epsilon-1)+1)\n",
    "    if action<0:\n",
    "        c=epsilon*action*p*np.sign(soc+action)\n",
    "    else:\n",
    "        c=epsilon*action*p\n",
    "    return(a-b+c)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'RBC')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "actions_desired=[0]*2+[0.2]*8+[0]*2+[-0.2]*8+[0]*4\n",
    "plt.scatter(range(24),actions_desired)\n",
    "plt.xticks(np.arange(24))\n",
    "plt.xlabel('hr of the day')\n",
    "plt.ylabel('action taken')\n",
    "plt.title('RBC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "reward_fun() missing 2 required positional arguments: 'action' and 'soc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4ddfa2ddb00f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#print(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mreward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mcum_reward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mq_s_dash_a_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reward_fun() missing 2 required positional arguments: 'action' and 'soc'"
     ]
    }
   ],
   "source": [
    "#basic on policy sarsa-working\n",
    "#using reward fucntion 1\n",
    "cost, cum_reward = {}, {}\n",
    "gamma=0.99\n",
    "alpha=0.1\n",
    "na=num_actions\n",
    "from collections import defaultdict\n",
    "state_action=defaultdict()\n",
    "w=np.ones((3,24))\n",
    "for ep in range(1):\n",
    "    print(ep)\n",
    "    cum_reward[ep]=[]\n",
    "    s = env.reset()[0][1]\n",
    "    state=generate_state(s)\n",
    "    done = False\n",
    "    i=0\n",
    "    while not done:\n",
    "        q_s_a_s=np.matmul(w,state.T)\n",
    "        action_ind=np.argmax(q_s_a_s)\n",
    "        \n",
    "        q_s=q_s_a_s[action_ind]\n",
    "        action=actions_space[action_ind]\n",
    "        state_action[s]=action\n",
    "        ns, reward, done, _ = env.step([[action]])\n",
    "        ns_=ns[0][1]\n",
    "        \n",
    "        next_state=generate_state(ns_)\n",
    "        #print(s)\n",
    "        reward=reward_fun(int(s)-1,action)\n",
    "        cum_reward[ep].append(reward)\n",
    "        q_s_dash_a_s=np.matmul(w,next_state)\n",
    "        epsilon=np.random.rand(1)\n",
    "        if epsilon<0.9:\n",
    "            action_index=np.argmax(q_s_dash_a_s)\n",
    "            action_dash=actions_space[action_index]\n",
    "            q_s_dash=np.max(q_s_dash_a_s)\n",
    "        else:\n",
    "            action_index=np.random.choice(na)\n",
    "            action_dash=actions_space[action_index]\n",
    "            q_s_dash=q_s_dash_a_s[action_index]\n",
    "        \n",
    "        temp=np.zeros((num_actions,24))\n",
    "        temp[action_ind,:]=state\n",
    "        w=w+alpha*(reward+gamma*q_s_dash-q_s)*(temp)\n",
    "        action=action_dash\n",
    "        state=next_state\n",
    "        s=ns_\n",
    "    delta=sum([abs(i-j) for i,j  in zip(list(state_action.values()),actions_desired)])\n",
    "    if delta==0:\n",
    "        break\n",
    "        \n",
    "    cost[ep] = env.cost()\n",
    "    print(cost[ep])    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b92782c443e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mq_s_a_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "#on policy sarsa\n",
    "from reward_function import reward_function\n",
    "\n",
    "actions_space=np.arange(-0.2,0.21,0.2)\n",
    "num_actions=actions_space.shape[0]\n",
    "\n",
    "actions_desired=[0]*2+[0.2]*8+[0]*2+[-0.2]*8+[0]*4\n",
    "\n",
    "cost, cum_reward = {}, {}\n",
    "gamma=0.99\n",
    "alpha=0.001\n",
    "na=num_actions\n",
    "from collections import defaultdict\n",
    "state_action=defaultdict()\n",
    "state_reward_t={0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0,13:0,14:0,15:0,16:0,17:0,18:0,19:0,20:0,21:0,22:0,23:0}\n",
    "state_reward_t_1={0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0,11:0,12:0,13:0,14:0,15:0,16:0,17:0,18:0,19:0,20:0,21:0,22:0,23:0}\n",
    "\n",
    "for ep in range(2):\n",
    "    print(ep)\n",
    "    \n",
    "    cum_reward[ep]=[]\n",
    "    sq = env.reset()\n",
    "    t_out=[sq[0][3]]\n",
    "    t_in=[sq[0][8]]\n",
    "    s=sq[0][1]\n",
    "    \n",
    "    state=generate_state(s)\n",
    "    done = False\n",
    "    i=0\n",
    "    \n",
    "    q_s_a_s=np.matmul(w,state.T)\n",
    "    epsilon=np.random.rand(1)\n",
    "\n",
    "    if epsilon<0.9:\n",
    "        action_index=np.argmax(q_s_a_s)\n",
    "        action=actions_space[action_index]\n",
    "        q_s=np.max(q_s_a_s)\n",
    "    else:\n",
    "        action_index=np.random.choice(na)\n",
    "        action=actions_space[action_index]\n",
    "        q_s=q_s_a_s[action_index]\n",
    "\n",
    "    i=0\n",
    "    while not done:\n",
    "        action_ind=action_index\n",
    "        state_action[s]=action\n",
    "        ns, reward, done, _ = env.step([[action]])\n",
    "        p=t_out[-1]-t_in[-1]\n",
    "        reward=reward[0]*p*10\n",
    "        state_reward_t[s]=reward\n",
    "        \n",
    "        cum_reward[ep].append(reward)\n",
    "        \n",
    "        t_out.append(ns[0][3])\n",
    "        t_in.append(ns[0][8])\n",
    "        ns_=ns[0][1]\n",
    "        \n",
    "        next_state=generate_state(ns_)\n",
    "        \n",
    "        q_s_dash_a_s=np.matmul(w,next_state)\n",
    "        epsilon=np.random.rand(1)\n",
    "        if epsilon<0.9:\n",
    "            action_index=np.argmax(q_s_dash_a_s)\n",
    "            action_dash=actions_space[action_index]\n",
    "            q_s_dash=np.max(q_s_dash_a_s)\n",
    "        else:\n",
    "            action_index=np.random.choice(na)\n",
    "            action_dash=actions_space[action_index]\n",
    "            q_s_dash=q_s_dash_a_s[action_index]\n",
    "        \n",
    "        temp=np.zeros((num_actions,24))\n",
    "        temp[action_ind,:]=state\n",
    "        \n",
    "        w=w+alpha*(reward+gamma*q_s_dash-q_s)*(temp)\n",
    "        action=action_dash\n",
    "        state=next_state\n",
    "        s=ns_\n",
    "        q_s=q_s_dash\n",
    "        \n",
    "    delta=sum([abs(i-j) for i,j  in zip(list(state_action.values()),actions_desired)])\n",
    " \n",
    "    cost[ep] = env.cost()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reward_fun' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0c1cefad6c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mreward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mstate_reward_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtemp_diff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reward_fun' is not defined"
     ]
    }
   ],
   "source": [
    "from reward_function import reward_function\n",
    "#reward function 3\n",
    "actions_space=np.arange(-0.2,0.21,0.2)\n",
    "num_actions=actions_space.shape[0]\n",
    "\n",
    "actions_desired=[0]*2+[0.2]*8+[0]*2+[-0.2]*8+[0]*4\n",
    "\n",
    "cost, cum_reward = {}, {}\n",
    "gamma=0.99\n",
    "alpha=0.1\n",
    "na=num_actions\n",
    "from collections import defaultdict\n",
    "state_action=defaultdict()\n",
    "\n",
    "mu=12.5\n",
    "i=0\n",
    "w=np.zeros((num_actions,24))\n",
    "for ep in range(1):\n",
    "    \n",
    "    diff=[]\n",
    "    cum_reward[ep]=[]\n",
    "    \n",
    "    sq = env.reset()\n",
    "    t_out=[sq[0][3]]\n",
    "    t_in=[sq[0][8]]\n",
    "    soc=sq[0][-2]\n",
    "    s=sq[0][1]\n",
    "    \n",
    "    state=generate_state(s)\n",
    "    done = False\n",
    "\n",
    "    state=generate_state(s)\n",
    "    q_s_a_s=np.matmul(w,state.T)\n",
    "    action=actions_space[np.argmax(q_s_a_s)]\n",
    "    action_index=np.argmax(q_s_a_s)\n",
    "    \n",
    "    while not done:\n",
    "        \n",
    "        temp=np.zeros((num_actions,24))\n",
    "        temp[action_index,:]=state\n",
    "        \n",
    "        state_action[s]=action\n",
    "        ns, reward, done, _ = env.step([[action]])\n",
    "        \n",
    "        reward=reward_fun(mu,t_out[-1],action,soc)\n",
    "        state_reward_t[s]=reward\n",
    "        temp_diff=t_out[-1]-t_in[-1]\n",
    "        diff.append(temp_diff)\n",
    "        \n",
    "        cum_reward[ep].append(reward)\n",
    "        \n",
    "        t_out.append(ns[0][3])\n",
    "        t_in.append(ns[0][8])\n",
    "        soc=ns[0][-2]\n",
    "        ns_=ns[0][1]\n",
    "        \n",
    "        next_state=generate_state(ns_)\n",
    "        \n",
    "        q_s_dash_a_s=np.matmul(w,next_state)\n",
    "        epsilon=np.random.rand(1)\n",
    "        \n",
    "        if epsilon<0.9:\n",
    "            action_index=np.argmax(q_s_dash_a_s)\n",
    "            action_dash=actions_space[action_index]\n",
    "            q_s_dash=np.max(q_s_dash_a_s)\n",
    "        else:\n",
    "            action_index=np.random.choice(na)\n",
    "            action_dash=actions_space[action_index]\n",
    "            q_s_dash=q_s_dash_a_s[action_index]\n",
    "        \n",
    "        \n",
    "        \n",
    "        w=w+alpha*(reward+gamma*q_s_dash-q_s)*(temp)\n",
    "        \n",
    "        action=action_dash\n",
    "        state=next_state\n",
    "        s=ns_\n",
    "        q_s=q_s_dash\n",
    "        \n",
    "    i=i+1\n",
    "    cost[ep] = env.cost()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'temp_diff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-41d0ea807e1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mreward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mcum_reward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_diff' is not defined"
     ]
    }
   ],
   "source": [
    "action_space=np.arange(-0.2,0.21,0.1)\n",
    "#mu is updated using median\n",
    "#reward fucntion 3\n",
    "cost, cum_reward = {}, {}\n",
    "gamma=0.9\n",
    "alpha=0.9\n",
    "na=5\n",
    "from collections import defaultdict\n",
    "state_action=defaultdict()\n",
    "#w=np.ones((5,24))\n",
    "cum_reward={}\n",
    "mu=12.5\n",
    "\n",
    "\n",
    "def reward_fun(mu,temp,action,soc,epsilon=0.01):\n",
    "    p=np.sign(mu-temp)\n",
    "    a=(p+1)*action\n",
    "    b=p*(np.sign(soc+p*action-epsilon-1)+1)\n",
    "    if action<0:\n",
    "        c=epsilon*action*p*np.sign(soc+action)\n",
    "    else:\n",
    "        c=epsilon*action*p\n",
    "    return(a-b+c)\n",
    "\n",
    "Q=np.zeros((24,10,5))\n",
    "for ep in range(40):\n",
    "    print(ep)\n",
    "    q=[]\n",
    "    states=[]\n",
    "    \n",
    "    sq = env.reset()\n",
    "    t_out=[sq[0][3]]\n",
    "    t_in=[sq[0][7]]\n",
    "    soc=sq[0][-2]\n",
    "    s=int(sq[0][1])\n",
    "    j_=int(np.ceil(soc*10))\n",
    "    if j_==10:\n",
    "        j_=9\n",
    "    ac=np.argmax(Q[s-1,j_-1,:])\n",
    "    action=action_space[ac]\n",
    "    done=False\n",
    "    diff=[]\n",
    "    cum_reward[ep]=[]\n",
    "    \n",
    "    while not done:\n",
    "        state_action[s]=action\n",
    "        ns, reward, done, _ = env.step([[action]])\n",
    "        reward=reward_fun(mu,t_out[-1],action,soc)\n",
    "        diff.append(temp_diff)\n",
    "        cum_reward[ep].append(reward)\n",
    "        \n",
    "        t_out.append(ns[0][3])\n",
    "        t_in.append(ns[0][7])\n",
    "        soc=ns[0][-2]\n",
    "        j=int(np.ceil(soc*10))\n",
    "        if j==10:\n",
    "            j=9\n",
    "        ns_ = int(ns[0][1])\n",
    "        \n",
    "        epsilon=np.random.rand(1)\n",
    "        temp=np.zeros((5,24))\n",
    "        temp[ac,:]=state\n",
    "        \n",
    "        if epsilon<=0.7:\n",
    "            ac_=np.argmax(Q[ns_-1,j,:])\n",
    "            action_dash=action_space[ac_]\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            ac_=np.random.choice(na)\n",
    "            action_dash=action_space[ac_]\n",
    "        Q[s-1,j_,ac]=Q[s-1,j_,ac]+alpha*(reward+gamma*Q[ns_-1,j,ac_]-Q[s-1,j_,ac] ) \n",
    "        state=next_state\n",
    "        action=action_dash\n",
    "        s=ns_\n",
    "        ac=ac_\n",
    "        mu=np.median(t_out)\n",
    "        j_=j\n",
    "    cost[ep] = env.cost()\n",
    "    print(cost[ep])\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
